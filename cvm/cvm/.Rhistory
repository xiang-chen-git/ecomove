H.s <- subset(Ant, Species=="Seed")$Headwidth2
H.t <- subset(Ant, Species=="Thatch")$Headwidth2
H.M <- outer(sort(H.t), sort(H.s), ">")
image(H.M, main="Head width", xlab="Seed Ants",
ylab="Thatch Ants", col=col[3:4])
sum(H.M > 0) / prod(table(Ant$Species))
nreps <- 1000; D.weight.sim <- rep(0, nreps)
for(i in 1:nreps)
D.weight.sim[i] <- getD.means(Ant$Weight, sample(Ant$Species))
D.head.sim <- rep(0, nreps)
for(i in 1:nreps)
D.head.sim[i] <- getD.means(Ant$Headwidth2, sample(Ant$Species))
EQ <- read.csv("http://neic.usgs.gov/neis/gis/qed.asc")
par(cex.lab=0.5, cex.axis=0.5, tck=0, mgp=c(1.5,.25,0), mar=c(3,3,1,1))
EQ$DateTime <- strptime(paste(EQ$Date, EQ$Time), format = "%Y/%m/%d %H:%M:%S")
hist(EQ$DateTime, col="grey", breaks=20, main="")
EQ.apr <- EQ$DateTime[EQ$DateTime$mon == 3]
EQ.apr
EQ$DateTime
EQ$DateTime$mon
EQ.apr <- EQ$DateTime[EQ$DateTime$mon == 4]
dEQ.apr <- na.omit(difftime(EQ.apr[-length(EQ.apr)], EQ.apr[-1], units="min"))
sort(dEQ.apr)
n <- length(dEQ.apr)
mean(dEQ.apr) + c(-1,1)*qt(0.975, df=n-1)*sd(dEQ.apr)/sqrt(n)
t.test(dEQ.apr)$conf.int
par(cex.lab=0.5, cex.axis=0.5, tck=0, mgp=c(1.5,.25,0), mar=c(3,3,1,1))
dim(EQ)
EQ$DateTime <- strptime(paste(EQ$Date, EQ$Time), format = "%Y/%m/%d %H:%M:%S")
hist(EQ$DateTime, col="grey", breaks=20, main="")
head(EQ)
range(EQ$DateTime)
EQ <- read.csv("http://neic.usgs.gov/neis/gis/qed.asc")
EQ$DateTime
EQ$DateTime <- strptime(paste(EQ$Date, EQ$Time), format = "%Y/%m/%d %H:%M:%S")
hist(EQ$DateTime, col="grey", breaks=20, main="")
EQ <- read.csv("http://earthquake.usgs.gov/earthquakes/feed/v1.0/summary/4.5_hour.csv")
head(EQ)
EQ <- read.csv("http://earthquake.usgs.gov/earthquakes/feed/v1.0/summary/all_month.csv")
head(EQ)
EQ$DateTime <- as.POSIXlt(EQ$time, format = "%Y-%m-%dT%H:%M:%S")
EQ$DateTime
hist(EQ$DateTime, col="grey", breaks=20, main="")
EQ.apr <- EQ$DateTime[EQ$DateTime$mon == 4]
dEQ.apr <- na.omit(difftime(EQ.apr[-length(EQ.apr)], EQ.apr[-1], units="min"))
sort(dEQ.apr)
head(EQ)
summary(EQ$mag)
EQ.apr <- subset(EQ, mag>4.5)
EQ.apr
dEQ.apr <- na.omit(difftime(EQ.apr[-length(EQ.apr)], EQ.apr[-1], units="min"))
EQ <- subset(EQ, mag>4.5)
dEQ <- na.omit(difftime(EQ[-length(EQ)], EQ[-1], units="min"))
EQ <- subset(EQ$time, mag>4.5)
EQ <- subset(EQ, mag>4.5)$time
dEQ <- na.omit(difftime(EQ[-length(EQ)], EQ[-1], units="min"))
sort(dEQ)
EQ <- read.csv("http://earthquake.usgs.gov/earthquakes/feed/v1.0/summary/all_month.csv")
par(cex.lab=0.5, cex.axis=0.5, tck=0, mgp=c(1.5,.25,0), mar=c(3,3,1,1))
EQ$DateTime <- as.POSIXlt(EQ$time, format = "%Y-%m-%dT%H:%M:%S")
hist(EQ$DateTime, col="grey", breaks=20, main="")
EQ$DateTime
dEQ <- na.omit(difftime(EQ$DateTime[-nrow(EQ)], EQ$DateTime[-1], units="min"))
sort(dEQ)
EQ <- subset(EQ, mag>4.5)
summary(EQ$mag)
range(EQ$DateTime)
EQ <- subset(EQ, mag>6)
dEQ <- na.omit(difftime(EQ$DateTime[-nrow(EQ)], EQ$DateTime[-1], units="min"))
sort(dEQ)
n <- length(dEQ.apr)
n
mean(dEQ.apr) + c(-1,1)*qt(0.975, df=n-1)*sd(dEQ.apr)/sqrt(n)
t.test(dEQ.apr)$conf.int
n <- length(dEQ)
mean(dEQ) + c(-1,1)*qt(0.975, df=n-1)*sd(dEQ)/sqrt(n)
dEQ
t.test(dEQ)$conf.int
EQ <- read.csv("http://earthquake.usgs.gov/earthquakes/feed/v1.0/summary/all_month.csv")
par(cex.lab=0.5, cex.axis=0.5, tck=0, mgp=c(1.5,.25,0), mar=c(3,3,1,1))
EQ$DateTime <- as.POSIXlt(EQ$time, format = "%Y-%m-%dT%H:%M:%S")
hist(EQ$DateTime, col="grey", breaks=20, main="")
EQ <- subset(EQ, mag>5)
dEQ <- na.omit(difftime(EQ$DateTime[-nrow(EQ)], EQ$DateTime[-1], units="min"))
sort(dEQ)
n <- length(dEQ)
mean(dEQ) + c(-1,1)*qt(0.975, df=n-1)*sd(dEQ)/sqrt(n)
EQ <- subset(EQ, mag>6)
dEQ <- na.omit(difftime(EQ$DateTime[-nrow(EQ)], EQ$DateTime[-1], units="min"))
sort(dEQ)
n <- length(dEQ)
mean(dEQ) + c(-1,1)*qt(0.975, df=n-1)*sd(dEQ)/sqrt(n)
t.test(dEQ)$conf.int
nreps <- 1000
mean.BS <- rep(0,nreps)
for(i in 1:nreps)
mean.BS[i] <- mean(sample(dEQ.apr, replace=TRUE))
quantile(mean.BS, c(0.025, 0.975))
nreps <- 1000
for(i in 1:nreps)
mean.BS <- rep(0,nreps)
mean.BS[i] <- mean(sample(dEQ, replace=TRUE))
quantile(mean.BS, c(0.025, 0.975))
sample(dEQ, replace=TRUE)
mean(sample(dEQ, replace=TRUE))
mean.BS
nreps <- 1000
mean.BS <- rep(0,nreps)
mean(sample(dEQ, replace=TRUE))
for(i in 1:nreps)
mean.BS[i] <- mean(sample(dEQ, replace=TRUE))
mean.BS
quantile(mean.BS, c(0.025, 0.975))
t.test(dEQ)$conf.int
mean.BS <- do(nreps) * mean(sample(dEQ.apr, replace=TRUE))
require(mosaic)
mean.BS <- do(nreps) * mean(sample(dEQ.apr, replace=TRUE))
quantile(mean.BS[,1], c(0.025, 0.975))
head(mean.BS)
mean.BS <- do(nreps) * mean(sample(dEQ, replace=TRUE))
head(mean.BS)
dEQ <- as.numeric(na.omit(difftime(EQ$DateTime[-nrow(EQ)], EQ$DateTime[-1], units="min")))
n <- length(dEQ)
mean(dEQ) + c(-1,1)*qt(0.975, df=n-1)*sd(dEQ)/sqrt(n)
t.test(dEQ)$conf.int
nreps <- 1000
mean.BS <- rep(0,nreps)
for(i in 1:nreps)
mean.BS[i] <- mean(sample(dEQ, replace=TRUE))
quantile(mean.BS, c(0.025, 0.975))
mean.BS <- do(nreps) * mean(sample(dEQ, replace=TRUE))
quantile(mean.BS[,1], c(0.025, 0.975))
median.BS <- do(nreps) * median(sample(dEQ, replace=TRUE))
quantile(median.BS[,1], c(0.025, 0.5, 0.975))
require(boot)
plot(EQ$mag, EQ$depth)
cor(EQ.mar$mag, EQ.mar$depth,  use= "complete.obs")
cor(EQ$mag, EQ$depth,  use= "complete.obs")
cor.bs <- boot(EQ[EQ$DateTime$mon == 3,],
function(x, i)
cor(x$Magnitude[i], x$Depth[i],
use= "complete.obs"),
R = 1000)
(CI <- quantile(cor.bs$t, c(0.025, 0.975)))
cor.bs <- boot(EQ[EQ$DateTime$mon == 3,],
function(x, i)
cor(x$mag[i], x$depth[i],
use= "complete.obs"),
R = 1000)
(CI <- quantile(cor.bs$t, c(0.025, 0.975)))
cor.bs <- boot(EQ,
function(x, i)
cor(x$mag[i], x$depth[i],
use= "complete.obs"),
R = 1000)
(CI <- quantile(cor.bs$t, c(0.025, 0.975)))
par(cex.lab=0.5, cex.axis=0.5, tck=0, mgp=c(1,.25,0), mar=c(3,3,1,1), lwd=1/2)
hist(cor.bs$t, col="grey", main="")
abline(v = CI, col=2, lwd=2)
Solea <- read.csv("./data/Solea.csv")
Y <- Solea$Solea_solea
X <- Solea$salinity
Sole.glm <- glm(Y ~ X, family = "binomial")
expit <- function(x) exp(x)/(1 + exp(x))
Sole.predict <- predict(Sole.glm, newdata = data.frame(X = 0:40), se.fit = TRUE)
Sole.bs <- data.frame(X,Y)
for(i in 1:100)
{
Sole.glm.bs <- glm(Y ~ X, data = Sole.bs[sample(1:nrow(Sole.bs), replace=TRUE),], family = "binomial")
Sole.predict.bs <- predict(Sole.glm.bs, newdata = data.frame(X = 0:40), se.fit = TRUE)
lines(0:40, expit(Sole.predict.bs$fit), col = rgb(0,1,0,.2), lwd = 2)
}
library(cvm)
setwd("c:/eli/research/EstimatingCVM")
source("./code/Functions05_SamplingFunctions.r")
Phyllis <- read.csv("./data/BowheadData3.csv")
head(Phyllis)
is(Phyllis$DateTime)
as.numeric(difftime(Phyllis$DateTime, Phyllis$DateTime[1], unit="hour"))
T <- as.numeric(difftime(Phyllis$DateTime, Phyllis$DateTime[1], unit="hour"))
T
Phyllis$DateTime <- as.POSIXct(Phyllis$DateTime)
Phyllis$DateTime
range(Phyllis$DateTime)
Phyllis$Hours <- difftime(Phyllis$DateTime, Phyllis$DateTime[1], units="hours")
head(Phyllis)
Phyllis$Hours <- as.numeric(difftime(Phyllis$DateTime, Phyllis$DateTime[1], units="hours"))
head(Phyllis)
save(Bowhead, "c:/eli/programming/ecomove/cvm/cvm/data/Bowhead.Rd")
Bowhead <- Phyllis
save(Bowhead, file= "c:/eli/programming/ecomove/cvm/cvm/data/Bowhead.Rd")
Phyllis$Date <- NULL
head(Phyllis)
Phyllis$WhaleID <- NULL
Phyllis <- Phyllis[,c(3,1:2,4:ncol(Phyllis))]
head(Phyllis)
Phyllis$RID
Phyllis$RID <- NULL
head(Phyllis)
Phyllis <- Phyllis[,c(3,1:2,4:ncol(Phyllis))]
save(Bowhead, file= "c:/eli/programming/ecomove/cvm/cvm/data/Bowhead.rda")
head(Phyllis)
getwd()
setwd("c:/eli/programming/ecomove/cvm/cvm")
load("./data/Bowhead.rda")
head(Bowhead)
Bowhead <- Phyllis
save(Bowhead, file= "c:/eli/programming/ecomove/cvm/cvm/data/Bowhead.rda")
dim(Bowhead)
Phyllis <- read.csv("./data/BowheadData3.csv")
setwd("c:/eli/research/EstimatingCVM")
source("./code/Functions05_SamplingFunctions.r")
Phyllis <- read.csv("./data/BowheadData3.csv")
filter <- which(diff(Phyllis$Hours) < 0.09)
Phyllis <- Phyllis[-filter,]
filter <- with(Phyllis, which(Mod(diff(z.km)/diff(Hours)) > 10)+1
)
filter
Phyllis <- Phyllis[-filter,]
dim(Phyllis)
Phyllis <- Phyllis[1:954,]
setwd("c:/eli/research/EstimatingCVM")
source("./code/Functions05_SamplingFunctions.r")
Phyllis <- read.csv("./data/BowheadData3.csv")
head(Phyllis)
Phyllis$DateTime <- as.POSIXct(Phyllis$DateTime)
Phyllis$Date <- NULL
Phyllis$WhaleID <- NULL
Phyllis$RID <- NULL
Phyllis <- Phyllis[,c(3,1:2,4:ncol(Phyllis))]
Phyllis$Hours <- as.numeric(difftime(Phyllis$DateTime, Phyllis$DateTime[1], units="hours"))
# Filter too close intervals
filter <- which(diff(Phyllis$Hours) < 0.09)
Phyllis <- Phyllis[-filter,]
# filter one hyper large velocity
filter <- with(Phyllis, which(Mod(diff(z.km)/diff(Hours)) > 10)+1)
Phyllis <- Phyllis[-filter,]
# delete last chunk of data with very large intervals
Phyllis <- Phyllis[1:954,]
Bowhead <- Phyllis
save(Bowhead, file= "c:/eli/programming/ecomove/cvm/cvm/data/Bowhead.rda")
require(ggmap)
head(Bowhead)
with(Bowhead, median(Long))
with(Bowhead, median(Lat))
basemap1 <- get_map(location = c(-52, 69), maptype = "terrain", zoom=8)
ggmap(basemap1)
ggmap(basemap1) + geom_path(data = Boyhead, mapping = aes(x = Long, y = Lat))
ggmap(basemap1) + geom_path(data = Bowhead, mapping = aes(x = Long, y = Lat))
with(Bowhead(mean(range(Long))))
with(Bowhead, mean(range(Long)))
with(Bowhead, mean(range(Lat)))
DiskoBay <- get_map(location = c(-53.4, 69), maptype = "terrain", zoom=8)
ggmap(DiskoBay) + geom_path(data = Bowhead, mapping = aes(x = Long, y = Lat))
?get_map
require(ggmap)
DiskoBay <- get_map(location = c(-53.4, 69), maptype = "satellite", zoom=9)
ggmap(DiskoBay) + geom_path(data = Bowhead, mapping = aes(x = Long, y = Lat))
data(Bowhead)
require(ggmap)
DiskoBay <- get_map(location = c(-53.4, 69), maptype = "terrain", zoom=8)
ggmap(DiskoBay) + geom_path(data = Bowhead, mapping = aes(x = Long, y = Lat))
require(crawl)
library(cvm)
?estimateCVM
T <- cumsum(rexp(100,1))
mycvm <- CVM2(T, nu, tau, v0)
estimateCVM(mycvm$Z,mycvm$T,CI=TRUE,method="fullL", parameters=c("tau", "nu"))
nu <- 10
tau <- 3
v0 <- 10
plot(mycvm$Z, asp=1, type="b")
T <- cumsum(rexp(100,1))
mycvm <- CVM2(T, nu, tau, v0)
plot(mycvm$Z, asp=1, type="b")
plot(mycvm$Z, asp=1, type="o", cex=0.5, pch=19)
estimateCVM(mycvm$Z,mycvm$T,CI=TRUE,method="fullL", parameters=c("tau", "nu"))
estimateCVM(mycvm$Z,mycvm$T,CI=TRUE,method="fullL")
estimateCVM(mycvm$Z,mycvm$T,CI=TRUE,method="crawl")
estimateCVM(mycvm$Z,mycvm$T,method="crawl")
estimateCVM(mycvm$Z,mycvm$T,CI=TRUE,method="fullL")
library(cvm)
nu <- 10
tau <- 2
v0 <- 10
T <- seq(0,100,.1)
mycvm <- CVM2(T, nu, tau, v0)
plot(mycvm$Z, asp=1, type="o", cex=0.5, pch=19)
estimateCVM(mycvm$Z,mycvm$T,CI=TRUE,method="vaf",diagnose=TRUE)
plot(mycvm$Z, asp=1, type="o", cex=0.5, pch=19, col=rgb(0,0,0,.5))
plot(mycvm$Z, asp=1, type="o", cex=0.5, pch=19, col=rgb(0,0,0,.1))
estimateCVM(mycvm$Z,mycvm$T,CI=TRUE,method="vaf",diagnose=TRUE)
plot(mycvm$Z, asp=1, cex=0.5, pch=19, col=rgb(0,0,0,.1))
estimateCVM(mycvm$Z,mycvm$T,CI=TRUE,method="vaf",diagnose=TRUE)
T <- seq(0,100,.1)
mycvm <- CVM2(T, nu, tau, v0)
plot(mycvm$Z, asp=1, cex=0.5, pch=19, col=rgb(0,0,0,.1))
estimateCVM(mycvm$Z,mycvm$T,CI=TRUE,method="vaf",diagnose=TRUE)
tau <- 2
T <- seq(0,1000,1)
mycvm <- CVM2(T, nu, tau, v0)
plot(mycvm$Z, asp=1, type="o", cex=0.5, pch=19)
estimateCVM(mycvm$Z,mycvm$T,CI=TRUE,method="vaf",diagnose=TRUE)
nu <- 10
tau <- 2
v0 <- 10
T <- seq(0,100,.1)
mycvm <- CVM2(T, nu, tau, v0)
plot(mycvm$Z, asp=1, cex=0.5, pch=19, col=rgb(0,0,0,.1))
estimateCVM(mycvm$Z,mycvm$T,CI=TRUE,method="vaf",diagnose=TRUE)
# coarser sampling
tau <- 2
T <- seq(0,1000,1)
mycvm <- CVM2(T, nu, tau, v0)
plot(mycvm$Z, asp=1, type="o", cex=0.5, pch=19)
estimateCVM(mycvm$Z,mycvm$T,CI=TRUE,method="vaf",diagnose=TRUE)
estimateCVM(mycvm$Z,mycvm$T,CI=TRUE,method="vaf",diagnose=TRUE, spline=TRUE)
estimateCVM(mycvm$Z,mycvm$T,CI=TRUE,method="vaf",diagnose=TRUE)
estimateCVM(mycvm$Z,mycvm$T,CI=TRUE,method="vaf",diagnose=TRUE)
estimateCVM(mycvm$Z,mycvm$T,CI=TRUE,method="vaf",spline=TRUE)
tau <- 1
nu <- 8
mycvm <- CVM2(T=1:1000, nu, tau)
plot(mycvm$Z, asp=1, type="o", cex=0.5, pch=19)
estimateCVM(mycvm$Z,mycvm$T,CI=TRUE,method="crw", diagnose=TRUE)
tau <- 100
mycvm <- CVM2(T=1:1000, nu, tau)
plot(mycvm$Z, asp=1, type="o", cex=0.5, pch=19)
estimateCVM(mycvm$Z,mycvm$T,method="crw", CI=TRUE, diagnose=TRUE)
estimateCVM(mycvm$Z,mycvm$T,CI=TRUE,method="crw", diagnose=TRUE)
mycvm <- CVM2(T=1:1000, nu, tau)
plot(mycvm$Z, asp=1, type="o", cex=0.5, pch=19)
estimateCVM(mycvm$Z,mycvm$T,CI=TRUE,method="crw", diagnose=TRUE)
tau <- 1
nu <- 8
mycvm <- CVM2(T=1:1000, nu, tau)
plot(mycvm$Z, asp=1, type="o", cex=0.5, pch=19)
estimateCVM(mycvm$Z,mycvm$T,CI=TRUE,method="crw", diagnose=TRUE)
tau <- 100
mycvm <- CVM2(T=1:1000, nu, tau)
plot(mycvm$Z, asp=1, type="o", cex=0.5, pch=19)
estimateCVM(mycvm$Z,mycvm$T,method="crw", CI=TRUE, diagnose=TRUE)
nu <- 10
tau <- 3
v0 <- 10
# irregular timing
T <- cumsum(rexp(1000,1/.1))
mycvm <- CVM2(T, nu, tau, v0)
plot(mycvm$Z, asp=1, type="o", cex=0.5, pch=19)
estimateCVM(mycvm$Z,mycvm$T,CI=TRUE,method="onestep", parameters=c("tau", "nu"))
T <- cumsum(rexp(1000,1))
mycvm <- CVM2(T, nu, tau, v0)
plot(mycvm$Z, asp=1, type="o", cex=0.5, pch=19)
estimateCVM(mycvm$Z,mycvm$T,CI=TRUE,method="onestep", parameters=c("tau", "nu"))
# improved with splining
estimateCVM(mycvm$Z,mycvm$T,CI=TRUE,method="onestep", parameters=c("tau", "nu"), spline=TRUE)
T <- cumsum(rexp(100,1))
mycvm <- CVM2(T, nu, tau, v0)
plot(mycvm$Z, asp=1, type="o", cex=0.5, pch=19)
estimateCVM(mycvm$Z,mycvm$T,CI=TRUE,method="fullL")
estimateCVM(mycvm$Z,mycvm$T,method="crawl")
nutau <- Get.nutau(Fit.crawl)
row.names(nutau) <- c("tau", "nu")
T <- cumsum(rexp(1000,1))
mycvm <- CVM2(T, nu, tau, v0)
plot(mycvm$Z, asp=1, type="o", cex=0.5, pch=19)
plot(mycvm$Z, asp=1, type="o", cex=0.5, pch=19, col=rgb(0,0,0,.5))
plot(mycvm$Z, asp=1, type="o", cex=0.5, pch=19, col=rgb(0,0,0,.2))
estimateCVM(mycvm$Z,mycvm$T,method="crawl")
library(cvm)
?estimateCVM
library(cvm)
library(cvm)
require(cvm)
require(CVM)
require(cvm)
install.packages("mvtnorm")
install.packages("RcppArmadillo")
install.packages("CircStats")
install.packages("numDeriv")
install.packages("crawl")
install.packages(knitr)
install.packages("knitr")
install.packages("roxygen2")
library(cvm)
?estimateCVM
?CVM
nu <- 2; tau <- 5; dt <- .1; cvm <- CVM(nu, tau, Tmax = 1000, dt = dt)
plot(cvm$Z, asp=1, type="l", main = "CVM(2,5)")
title(sub = "0-1000 time units")
?estimateCVM
library(cvm)
library(cvm)
?estimateCVM
?CVM
?estimateCVM
estimateCVM <- function(Z, T, method = c("vaf", "crw", "onestep", "fullL")[1], ...)
{
if(method == "crw")
return(estimateCVM.crw(Z,T,...))
if(method == "vaf")
return(estimateCVM.vaf(Z,T,...))
if(method == "onestep")
return(estimateCVM.onestep(Z,T,...))
if(method == "fullL")
return(estimateCVM.fullL(Z,T,...))
if(method == "crawl")
return(estimateCVM.crawl(Z,T,...))
}
estimateCVM
function(Z, T, method = c("vaf", "crw", "onestep", "fullL")[1], ...)
{
if(method == "crw")
return(estimateCVM.crw(Z,T,...))
if(method == "vaf")
return(estimateCVM.vaf(Z,T,...))
if(method == "onestep")
return(estimateCVM.onestep(Z,T,...))
if(method == "fullL")
return(estimateCVM.fullL(Z,T,...))
if(method == "crawl")
return(estimateCVM.crawl(Z,T,...))
}
library(cvm)
?estimateCVM
?CVM
?estimateCVM
?CVM
library(cvm)
?estimateCVM
library(cvm)
?estimateCVM
nu <- 10
nu <- 10
tau <- 2
v0 <- 10
T <- seq(0,100,.1)
mycvm <- CVM2(T, nu, tau, v0)
plot(mycvm$Z, asp=1, cex=0.5, pch=19, col=rgb(0,0,0,.1))
estimateCVM(mycvm$Z,mycvm$T,CI=TRUE,method="vaf",diagnose=TRUE)
# coarser sampling
tau <- 2
T <- seq(0,1000,1)
mycvm <- CVM2(T, nu, tau, v0)
plot(mycvm$Z, asp=1, type="o", cex=0.5, pch=19)
estimateCVM(mycvm$Z,mycvm$T,CI=TRUE,method="vaf",diagnose=TRUE)
# improved speed estimate because of spline
estimateCVM(mycvm$Z,mycvm$T,CI=TRUE,method="vaf",spline=TRUE)
#----------------------------------------------------------
# Example 2: CRW method (low resolution, regular sampling)
#----------------------------------------------------------
tau <- 1
nu <- 8
mycvm <- CVM2(T=1:1000, nu, tau)
plot(mycvm$Z, asp=1, type="o", cex=0.5, pch=19)
estimateCVM(mycvm$Z,mycvm$T,CI=TRUE,method="crw", diagnose=TRUE)
# Example 2b: CRW method, poor diagnostics (auto-correlated step-lengths)
tau <- 100
mycvm <- CVM2(T=1:1000, nu, tau)
plot(mycvm$Z, asp=1, type="o", cex=0.5, pch=19)
estimateCVM(mycvm$Z,mycvm$T,method="crw", CI=TRUE, diagnose=TRUE)
#--------------------------------------------------------------------------------
# Example 3: One-step likelihood method (higher resolution, irregular sampling)
#--------------------------------------------------------------------------------
nu <- 10
tau <- 3
v0 <- 10
# irregular timing
T <- cumsum(rexp(1000,1/.1))
mycvm <- CVM2(T, nu, tau, v0)
plot(mycvm$Z, asp=1, type="o", cex=0.5, pch=19)
estimateCVM(mycvm$Z,mycvm$T,CI=TRUE,method="onestep", parameters=c("tau", "nu"))
# low resolution example
T <- cumsum(rexp(1000,1))
mycvm <- CVM2(T, nu, tau, v0)
plot(mycvm$Z, asp=1, type="o", cex=0.5, pch=19)
estimateCVM(mycvm$Z,mycvm$T,CI=TRUE,method="onestep", parameters=c("tau", "nu"))
# improved with splining
estimateCVM(mycvm$Z,mycvm$T,CI=TRUE,method="onestep", parameters=c("tau", "nu"), spline=TRUE)
estimateCVM(mycvm$Z,mycvm$T,method="crawl")
T <- cumsum(rexp(1000,1))
mycvm <- CVM2(T, nu, tau, v0)
plot(mycvm$Z, asp=1, type="o", cex=0.5, pch=19, col=rgb(0,0,0,.2))
estimateCVM(mycvm$Z,mycvm$T,method="crawl")
nu <- 10; tau <- 3; v0 <- 10
T <- cumsum(rexp(100,1))
mycvm <- CVM2(T, nu, tau, v0)
plot(mycvm$Z, asp=1, type="o", cex=0.5, pch=19)
estimateCVM(mycvm$Z,mycvm$T,CI=TRUE,method="fullL")
T <- cumsum(rexp(1000,1))
mycvm <- CVM2(T, nu, tau, v0)
plot(mycvm$Z, asp=1, type="o", cex=0.5, pch=19)
estimateCVM(mycvm$Z,mycvm$T,CI=TRUE,method="onestep", parameters=c("tau", "nu"))
?dmvnorm2
?dmvnorm2
T <- cumsum(rexp(1000,1))
mycvm <- CVM2(T, nu, tau, v0)
plot(mycvm$Z, asp=1, type="o", cex=0.5, pch=19)
estimateCVM(mycvm$Z,mycvm$T,CI=TRUE,method="onestep", parameters=c("tau", "nu"))
# improved with splining
estimateCVM(mycvm$Z,mycvm$T,CI=TRUE,method="onestep", parameters=c("tau", "nu"), spline=TRUE)
require(bcpa)
vignette("bcpa")
?CVM
library(cvm)
vignette("cvm")
library(cvm)
vignette("cvm")
library(cvm)
vignette("cvm")
library(cvm)
vignette("cvm")
